{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeQBFiUf3Pc1"
      },
      "source": [
        "# Model inference\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "nTNO7I4K3WZ8"
      },
      "source": [
        "# I Perkenalan\n",
        "=================================================\n",
        "\n",
        "Nama : Gieorgie Kharismatik Kosasih\n",
        "\n",
        "Dataset : [data](https://www.kaggle.com/datasets/andrewmvd/trip-advisor-hotel-reviews)\n",
        "\n",
        "Deployment : [model deployment](https://huggingface.co/spaces/Gieorgie/Tripadvisior_Sentiment_Analysis)\n",
        "\n",
        "================================================="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUt-89sU3duk"
      },
      "source": [
        "Pada notebook ini model akan diuji dengan data inference untuk melihat apakah model dapat memprediksi dengan baik."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0001sdhF3pXk"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZP7tHCv3v4r",
        "outputId": "334886a4-a815-4d7a-89d0-20357081706b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb-aXEHr1oFp",
        "outputId": "a5d14469-b0bf-4083-be75-bb3fc9e03a45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "# preprocess\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "from collections import Counter\n",
        "nltk.download('stopwords') # Stopwords\n",
        "nltk.download('punkt') # Punctuation\n",
        "nltk.download('wordnet') # Wordnet\n",
        "nltk.download('omw-1.4')\n",
        "import contractions\n",
        "# model\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4PUqRja49EU"
      },
      "source": [
        "# Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb5ko4f45jU9",
        "outputId": "42a143d0-4184-4ebf-8abc-3581861f58a7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Skipping variable loading for optimizer 'Adam', because it has 1 variables whereas the saved optimizer has 55 variables. \n"
          ]
        }
      ],
      "source": [
        "model = load_model('best_model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu2ZUXBA-NaM"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OwztQ1A24g_U"
      },
      "outputs": [],
      "source": [
        "# Define stopwords\n",
        "stopwords_nltk = list(set(stopwords.words('english')))\n",
        "stopwords_add = ['hotel','room']\n",
        "stopwords_all = stopwords_nltk + stopwords_add\n",
        "\n",
        "# Define lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Make a function of text preprocessing\n",
        "\n",
        "def clean_review(review):\n",
        "\n",
        "    # make text lowercase\n",
        "    review = review.lower()\n",
        "\n",
        "    # fix contractions\n",
        "    review = contractions.fix(review)\n",
        "\n",
        "    # remove word with only 3 char\n",
        "    review = re.sub(r'\\b\\w{1,3}\\b', \" \",review)\n",
        "\n",
        "    # remove punctuation\n",
        "    review = re.sub('[%s]' % re.escape(string.punctuation), '', review)\n",
        "\n",
        "    # remove words containing numbers\n",
        "    review = re.sub('\\w*\\d\\w*', '', review)\n",
        "\n",
        "    # remove non-latin words\n",
        "    review = re.sub('[^\\x00-\\x7f]', '', review)\n",
        "\n",
        "    # remove non-words (emoji, etc.)\n",
        "    review = re.sub(\"[^A-Za-z\\s']\", \" \", review)\n",
        "\n",
        "    # remove underscores\n",
        "    review =  str.replace(review, '_', '')\n",
        "\n",
        "    # remove whitespace\n",
        "    review = review.strip()\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(review)\n",
        "\n",
        "    # Remove Stopwords\n",
        "    review = [word for word in tokens if word not in stopwords_all]\n",
        "\n",
        "    # Lemmatize the word\n",
        "    sentence = []\n",
        "    for word in review:\n",
        "      sentence.append(lemmatizer.lemmatize(word))\n",
        "    # combine\n",
        "    review = ' '.join(sentence)\n",
        "\n",
        "    return review\n",
        "\n",
        "def prediction(model, X):\n",
        "  y_pred = model.predict(X)\n",
        "  predictions = np.argmax(y_pred, axis=1)\n",
        "  for index, val in enumerate(predictions):\n",
        "    if val == 0:\n",
        "      print(f\"Review ini termasuk review negatif\")\n",
        "    elif val == 1:\n",
        "      print(f\"Review ini termasuk review neutral\")\n",
        "    else:\n",
        "      print(f\"Review ini termasuk review postive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-9SrfIR_6JRd"
      },
      "source": [
        "# Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Nzm1Hxkm57I8"
      },
      "outputs": [],
      "source": [
        "# input data inference\n",
        "inf1 = 'Great stay! Friendly staff, smooth check-in, and clean, spacious rooms with modern amenities. Delicious breakfast with plenty of options. Perfect location near attractions and shopping. Well-maintained pool and gym. Highly recommended!'\n",
        "inf2 = 'Disappointing stay. Long check-in, outdated and unclean room, faulty AC, and slow Wi-Fi. Limited, poor-quality breakfast. Unfriendly staff and noisy environment. Needs improvement.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "53nwOSbr6SJk"
      },
      "outputs": [],
      "source": [
        "# preprocessing\n",
        "x = clean_review(inf1)\n",
        "y = clean_review(inf2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkIrXtGC9fok",
        "outputId": "fec12ee1-3579-4960-e10f-ce58e23a5698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "Review ini termasuk review postive\n",
            "Review ini termasuk review negatif\n"
          ]
        }
      ],
      "source": [
        "# predict\n",
        "prediction(model, [x,y])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sb6wQMmB-FXN"
      },
      "source": [
        "model berhasil memprediksi dengan baik."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
